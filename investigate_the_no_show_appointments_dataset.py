# -*- coding: utf-8 -*-
"""Copy of Investigate the No-show Appointments Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NzllSjUzptkRKDuOMuaQNQKxeW6s2yEW

**As a data engineer, you are required to investigate the Medical Appointment No Shows dataset. The dataset contains information about a set of doctor appointments. The goal is to investigate why a patient does not show up for his/her appointment.**
**The dataset contains 110527 entries and 14 columns. It shows basic information about a set of doctor appointments.**

# **Task 1** : Investigate the dataset

## Initializing Data
"""

# Importing Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import datetime as dt
import seaborn as sns

# Load data to a dataframe
df = pd.read_csv('KaggleV2-May-2016.csv')

df.shape

# Printing out column names in data
df.columns

# Correcting typos in the column names 
df.columns = ['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay','AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension','Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'no_show']
df.columns

df.info()

# Checking an initial view on the data
df.head()

"""## Investigate the distribution of the show-ups."""

# Percentage of patients who show-up
plt.pie(df.no_show.value_counts(),labels=('No',' Yes'),autopct='%.2f%%', explode=(0, .05));
plt.title('Show vs No Show');

"""`The figure above shows that just 20% of appointments are no show and the rest attended.`

## Investigate the distribution of the gender.
"""

# Printing the unique values in column 'Gender'
print("Unique Values in `Gender` => {}".format(df.Gender.unique()))

# Percentage of Males vs Females appointments
plt.pie(df.Gender.value_counts(),labels=('F',' M'),autopct='%.2f%%', explode=(0, .05));
plt.title('Gender Distribution');

"""## Investigate the distribution of the number of days between the appointment date and the scheduling date.

The ScheduledDay and AppointmentDay columns type should be changed to datetime.
"""

# The ScheduledDay and AppointmentDay columns type should be changed to datetime
df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay']).dt.date.astype('datetime64[ns]')
df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay']).dt.date.astype('datetime64[ns]')

df.info()

"""Create a new column for the number of days between the appointment date and the scheduling date."""

# Create a new column for the number of days between the appointment date and the scheduling date
df['WaitingDays'] = (df.AppointmentDay - df.ScheduledDay).dt.days 
df.info()

# Print unique values in column 'WaitingDays'
print("Unique Values in `WaitingDays` => {}".format(df.WaitingDays.unique()))

# Awaiting time can not be less than 0 (where schedule day is the same as appointment day). Appointments cannot happen before it is scheduled.
print('Before change: {}'.format(df[(df.WaitingDays < 0)].WaitingDays.value_counts()))

# Remove all records with such values.
df = df[(df.WaitingDays >= 0)]

# Check if any WaitingDays values below 0 are left in the dataset.
print('After change: {}'.format(df[(df.WaitingDays < 0)].WaitingDays.value_counts()))

# Plot a relation between number of patients and their awaiting days
plt.figure(figsize=(20,4))
plt.xticks(rotation=0)
ax = sns.countplot(x=df.WaitingDays)
ax.set_title("Number of patients by number of days between the appointment date and the scheduling date")
plt.show()

# Counting the awaiting days where WaitingDays == 0
Waiting0 = df[(df.WaitingDays == 0)].WaitingDays.value_counts()
Waiting0

"""`It is worth to notice that almost 40k patients scheduled their visit for the same day.`


"""

# Plot WaitingDays
sns.stripplot(data = df, y = 'WaitingDays', jitter = True)
plt.ylim(0, 200)
plt.show();

"""`It seems that most of the appointments happen within 100 days (3 months) from being scheduled`

## Investigate whether the appointment date is a weekday or a weekend.

Create a new column to investigate whether the appointment day of the week is a weekday or a weekend.
"""

# Create a new column to investigate whether the appointment day of the week is a weekday or a weekend
# Create AppointmentDOW (appointment day of the week) column
df['AppointmentDOW'] = df.ScheduledDay.dt.day_name()

df['AppointmentDOW'].value_counts()

# Print the unique values in column 'AppointmentDOW'
print("Unique Values in `AppointmentDOW` => {}".format(df.AppointmentDOW.unique()))

# Plot the distribution of appointment days 
plt.pie(df.AppointmentDOW.value_counts(),labels = ('Tuesday', 'Wednesday', 'Monday', 'Friday', 'Thursday', 'Saturday'), autopct='%.2f%%');
plt.title('Appointment Day Of the Week Distribution');

# Create column 'IsWeekend' 
df["IsWeekend"] = df["AppointmentDOW"] == 'Saturday'

# Print the unique values in column 'IsWeekend'
print("Unique Values in `IsWeekend` => {}".format(df.IsWeekend.unique()))

# Plot 'IsWeekend'
plt.pie(df.IsWeekend.value_counts(),labels = ('Weekday', 'Weekend'), autopct='%.2f%%');
plt.title('Appointment Day Of the Week Distribution (Weekday vs Weekend)');

"""## Investigate whether the scheduling date is a weekday or a weekend.

Create a new column to investigate whether the schedule day of the week is a weekday or a weekend.
"""

# Create a new column to investigate whether the scheduling day of the week is a weekday or a weekend
# Create ScheduleDOW (schedule day of the week) column
df['ScheduleDOW'] = df.AppointmentDay.dt.day_name()

df['ScheduleDOW'].value_counts()

# Print unique values in column 'ScheduleDOW'
print("Unique Values in `ScheduleDOW` => {}".format(df.ScheduleDOW.unique()))

# Plot the distribution of scheduling days 
plt.pie(df.ScheduleDOW.value_counts(),labels = ('Tuesday', 'Wednesday', 'Monday', 'Friday', 'Thursday', 'Saturday'), autopct='%.2f%%');
plt.title('Schedule Day Of the Week Distribution');

# Create column 'IsWeekend2' 
df["IsWeekend2"] = df["ScheduleDOW"] == 'Saturday'

# Print the unique values in column 'IsWeekend2' 
print("Unique Values in `IsWeekend` => {}".format(df.IsWeekend2.unique()))

# Plot 'IsWeekend2'
plt.pie(df.IsWeekend2.value_counts(),labels = ('Weekday', 'Weekend'), autopct='%.2f%%');
plt.title('Schedule Day Of the Week Distribution (Weekday vs Weekend)');

"""# **Question (1)** : Who are the patients with the highest number of no-show-ups?"""

# Changing PatientId from float to integer
df.PatientId = df.PatientId.astype('int64')

# Create variables for ShowUps and NoShowUps
not_show = df.no_show=="Yes"
show_up = df.no_show=="No"

# Explore no-show for each PatientId
df.PatientId[not_show].value_counts()

"""# **Question (2)** : What are the health conditions of patients with the highest number of no-show-ups?"""

# Create a new DataFrame 'df.ns' 
df.ns = df[['PatientId','Hipertension', 'Diabetes', 'Alcoholism', 'Handcap', 'no_show' ]]
df.ns.columns = ['PatientId','Hipertension', 'Diabetes', 'Alcoholism', 'Handcap', 'no_show']

# Create a copy of 'not_show' column
df.ns['not_show'] = df.loc[:, 'no_show']

# Replace values in the new column 'no_show' to (1,0)
df.ns = df.ns.replace({'not_show': {'Yes': 1, 'No': 0}})
df.ns.not_show = df.ns.not_show.astype('int64')

# Create a new column 'NumberOfNoShowUps' to sum the number of 'not_show' days for each 'PatientId'
df.ns['NumberOfNoShowUps'] = df.ns.groupby(['PatientId'])['not_show'].transform(sum)



# Create a new DataFrame 'df_ns2' to sort column 'NumberOfNoShowUps' descendingly
df_ns2 = df.ns.sort_values("NumberOfNoShowUps", ascending=False)
# Drop duplicated 'PatientId' 
df_ns2.duplicated(['PatientId','not_show']).sum()
# Drop unimportant columns
df_ns2.drop_duplicates(['PatientId','not_show'],inplace=True)
df_ns2.drop(['no_show', 'not_show'],axis= 1,inplace=True )
# Print the health conditions of patients with the highest number of no-show-ups
df_ns2

"""# **Question (3)** : Who are the patients with the least number of no-show-ups?"""

# Create a new DataFrame 'df_ns3' to sort column 'NumberOfNoShowUps' ascendingly
df_ns3 = df.ns.sort_values("NumberOfNoShowUps", ascending=True)
# Drop duplicated 'PatientId' 
df_ns3.duplicated(['PatientId','not_show']).sum()
# Drop unimportant columns
df_ns3.drop_duplicates(['PatientId','not_show'],inplace=True)
df_ns3.drop(['no_show', 'not_show', 'Hipertension', 'Diabetes', 'Alcoholism', 'Handcap'],axis= 1,inplace=True )
# Print patients with the least number of no-show-ups
df_ns3

"""# **Question (4)** : What are the health conditions of patients with the least number of no-show-ups?"""

# Create a new DataFrame 'df_ns4' to sort column 'NumberOfNoShowUps' ascendingly
df_ns4 = df.ns.sort_values("NumberOfNoShowUps", ascending=True)
# Drop duplicated 'PatientId' 
df_ns4.duplicated(['PatientId','not_show']).sum()
# Drop unimportant columns
df_ns4.drop_duplicates(['PatientId','not_show'],inplace=True)
df_ns4.drop(['no_show', 'not_show'],axis= 1,inplace=True )
# Print the health conditions of patients with the least number of no-show-ups
df_ns4

"""# **Question (5)** : What are the neighborhoods with the highest no-show-ups?"""

# Create new DataFrame 'df.ng' for columns 'Neighbourhood' and 'no_show'
df.ng = df[['Neighbourhood', 'no_show' ]]
df.ng.columns = ['Neighbourhood', 'no_show']

# Create a copy of 'not_show' column
df.ng['not_show'] = df.ng.loc[:, 'no_show']

# Replace values in column 'no_show' to (1,0)
df.ng = df.ng.replace({'not_show': {'Yes': 1, 'No': 0}})
df.ng.not_show = df.ng.not_show.astype('int64')

# Create a new column 'NumberOfNoShowUps' to sum the number of 'not_show' days for each 'Neighbourhood'
df.ng['NumberOfNoShowUps'] = df.ng.groupby(['Neighbourhood'])['not_show'].transform(sum)

# Create a new DataFrame 'df_ns2' to sort column 'NumberOfNoShowUps' descendingly
df_ng2 = df.ng.sort_values("NumberOfNoShowUps", ascending=False)
# Drop duplicated 'Neighbourhood' 
df_ng2.duplicated(['Neighbourhood','no_show']).sum()
df_ng2.drop_duplicates(['Neighbourhood'],inplace=True)
# Drop unimportant columns
df_ng2.drop(['no_show'],axis= 1,inplace=True )
# Print the neighborhoods with the highest no-show-ups
df_ng2

"""# **Task 2** : Train a machine learning model to classify the dataset.

*Classification accuracy is the ratio of number of correct predictions to the total number of input samples, we calculated the accuracy of multiple classification algorithms through this code to choose the most suitable way of classification.*
"""

from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm, tree
import xgboost
from sklearn.model_selection import train_test_split

#Create Dependent and Independent Datasets based on our Dependent #and Independent features
X  = df[['Age', 'Gender','Scholarship', 'Hipertension', 'Diabetes',  'Alcoholism', 'Handcap', 'SMS_received', 'WaitingDays']]
y= df['no_show']

#Split the Data into Training and Testing sets with test size as #30%
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, shuffle=True)
 
classifiers = []
 
model1 = xgboost.XGBClassifier()
classifiers.append(model1)
model2 = svm.SVC()
classifiers.append(model2)
model3 = tree.DecisionTreeClassifier()
classifiers.append(model3)
model4 = RandomForestClassifier()
classifiers.append(model4)
model5 = LogisticRegression()
classifiers.append(model5)
model6 =  KNeighborsClassifier()
classifiers.append(model6)
 
for clf in classifiers:
    clf.fit(X_train, y_train)
    y_pred= clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print("Accuracy of %s is %s"%(clf, acc))
    cm = confusion_matrix(y_test, y_pred)
    print("Confusion Matrix of %s is %s"%(clf, cm))

df.info()

# Change data types in non int columns 
# Replace values in column 'no_show' to (1,0)
df = df.replace({'no_show': {'Yes': 1, 'No': 0}})
df.no_show = df.no_show.astype('int64')

# Replace values in column 'Gender' to (1,0)
df = df.replace({'Gender': {'F': 1, 'M': 0}})
df.Gender = df.Gender.astype('int64')

df.head()

# Select certain features from dataset for testing
feature_cols = ['Age', 'Gender','Scholarship', 'Hipertension', 'Diabetes',  'Alcoholism', 'Handcap', 'SMS_received', 'WaitingDays']

# Split dataset in features and target variable
X = df[feature_cols].values
y = df["no_show"].values

# Split data into training and testing data
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state=22)

len(x_train), len(x_test)

# Import Decision Tree Classifier
from sklearn import tree
# Create Decision Tree classifer object
X = x_train
Y = y_train
clf = tree.DecisionTreeClassifier(max_depth =4)
# Train Decision Tree Classifer
clf = clf.fit(X , Y)

# Plot Decision Tree
tree.plot_tree(clf)

#Predict the response for test dataset
y_pred = clf.predict(x_test)

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics 
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# https://pypi.python.org/pypi/pydot
!apt-get -qq install -y graphviz && pip install pydot
import pydot

pip install six

# Using Scikit-learn's export_graphviz function for display the decision tree. For plotting tree, we also to install graphviz and pydotplus.
# export_graphviz function converts decision tree classifier into dot file and pydotplus convert this dot file to png or displayable form on Jupyter.
from six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
dot_data = StringIO()
export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names = feature_cols , class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('noshow.png')
Image(graph.create_png())

# from sklearn import datasets
# from sklearn import svm
# clf2 = svm.SVC(kernel='linear')
# clf2.fit(X, Y)

# def plot_svc_decision_function(model, ax=None, plot_support=True):
#     """Plot the decision function for a 2D SVC"""
#     if ax is None:
#         ax = plt.gca()
#     xlim = ax.get_xlim()
#     ylim = ax.get_ylim()
    
#     # create grid to evaluate model
#     x = np.linspace(xlim[0], xlim[1], 30)
#     y = np.linspace(ylim[0], ylim[1], 30)
#     Y, X = np.meshgrid(y, x)
#     xy = np.vstack([X.ravel(), Y.ravel()]).T
#     P = model.decision_function(xy).reshape(X.shape)
    
#     # plot decision boundary and margins
#     ax.contour(X, Y, P, colors='k',
#                levels=[-1, 0, 1], alpha=0.5,
#                linestyles=['--', '-', '--'])
    
#     # plot support vectors
#     if plot_support:
#         ax.scatter(model.support_vectors_[:, 0],
#                    model.support_vectors_[:, 1],
#                    s=300, linewidth=1, facecolors='none');
#     ax.set_xlim(xlim)
#     ax.set_ylim(ylim)

# # plt.scatter(X[:, 0], X[:, 1], X[:,2], X[:,3], X[:,4], X[:,5], X[:,6], X[:,7], X[:,8], c=Y, s=50, cmap='autumn')
# plt.scatter(x_train[:,0], y_train[:,1] , c=y_train, s=50, cmap='autumn')

# plot_svc_decision_function(clf2);

# from sklearn import datasets
# from sklearn import svm

# h = .02  # step size in the mesh

# # we create an instance of SVM and fit out data. We do not scale our
# # data since we want to plot the support vectors

# C = 1.0  # SVM regularization parameter
# svc = svm.SVC(kernel='linear', C=C).fit(X, Y)
# rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(X, Y)
# poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(X, Y)
# lin_svc = svm.LinearSVC(C=C).fit(X, Y)

# # create a mesh to plot in
# x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
# y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
# xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
#                      np.arange(y_min, y_max, h))

# # title for the plots
# titles = ['SVC with linear kernel',
#           'LinearSVC (linear kernel)',
#           'SVC with RBF kernel',
#           'SVC with polynomial (degree 3) kernel']


# for i, clf in enumerate((svc, lin_svc, rbf_svc, poly_svc)):
#     # Plot the decision boundary. For that, we will assign a color to each
#     # point in the mesh [x_min, x_max]x[y_min, y_max].
#     plt.subplot(2, 2, i + 1)
#     plt.subplots_adjust(wspace=0.4, hspace=0.4)

#     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

#     # Put the result into a color plot
#     Z = Z.reshape(xx.shape)
#     plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)

#     # Plot also the training points
#     plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)
#     plt.xlabel('Sepal length')
#     plt.ylabel('Sepal width')
#     plt.xlim(xx.min(), xx.max())
#     plt.ylim(yy.min(), yy.max())
#     plt.xticks(())
#     plt.yticks(())
#     plt.title(titles[i])

# plt.show()